---
title: "Markov Chain Monte Carlo Sampling"
author: "Michele Scandola"
date: "$2^{nd}$ BayesHSC Summer School 2021"
font-family: 'Serif'
output:
  slidy_presentation:
    incremental: yes
    footer: "M. Scandola - $2^{nd}$ BayesHSC Summer School 2021 - https://michelescandola.shinyapps.io/2021_-_sipf_webinar_bayesian/"
css: mystyle.css
bibliography: biblio.bib
runtime: shiny
---

```{r setup, include=FALSE}
# Presentazione preparata da Michele Scandola per la Summer School
# BayesHSC
# 31/05 - 6/08 del 2021
# 
# Licenza afl-3.0

library(knitr)
library(ggplot2)
library(MASS)
library(bayesplot)

knitr::opts_chunk$set(echo = FALSE)
```

# Once upon a time... King Markov and Captain Metropolis

## Once upon a time... King Markov and Captain Metropolis 1/3

<div class = "box">
<center>
![](drunkking.jpg)
</center>

King Markov is king of a chain of 5 islands.

* Rather than live in a palace, he lives in a royal boat.
* Each night the royal boat anchors in the harbor of one of the islands.
* The law declares that the king must harbor at each island in
  proportion to the population of the island.
  
</div>
  
## Once upon a time... King Markov and Captain Metropolis 2/3

<div class = "box">
<center>
![](island.jpg)
</center>

Everyone else could find a perfectly reasonable way to visit each island,
but King Markov does not:

1. want to keep recording of the population of each island
2. he doesn't want to know each night where he will be the next night
</div>


## Once upon a time... King Markov and Captain Metropolis 3/3

<div class = "box">
<center>
<img src="coin.jpg" alt="drawing" width="300"/>
</center>

Metropolis, the captain of the boat, in order to choose the next island

1. Each morning, have breakfast with the island clerk and inquire
   about the population of the current island.
2. He randomly choose a different island, and he travels there for lunch
3. Over lunch at the proposal island, inquire about its population.
  * If the proposal island has more people, stay at the proposal island for the
    night.
  * If the proposal island has fewer people,
    he flips a coin, and if it is "tail" they stay, if it is "head" they move
    to the last island
</div>
    
## Once upon a time... King Markov and Captain Metropolis

```{r}
sidebarPanel(
  sliderInput("N0", label = "Number of King Markov's travels:",
                min = 10, max = 1350, value = 10, step = 10),
  width = 15
)

renderPlot({
  old.par <- par()
  
  dat0 <- c(1:5, 2:5, 3:5, 4:5, 5)
  dat0 <- c( dat0, dat0, dat0 , dat0, dat0, dat0 , dat0, dat0, dat0 )
  
  f <- function(x) { return( x ) }
  
  n0 <- as.numeric(input$N0)
  
  myMCMC_step <- function(old_point, density_function, datt){
      new_point <- sample( datt )[1]
      
      ## Acceptance probability:
      alpha <- min(1, density_function(new_point) / density_function(old_point))
      
      ## Accept new point with probability alpha:
      if (alpha > 1){ # the population of the new island is bigger
        return( new_point )
      } else {
        if( rbinom(n = 1, size = 1, prob = 0.5) == 0 ){ ## tails
          return( old_point )
        } else { ## heads
          return( new_point )
        }
      }
  }
  
  set.seed( 5 )
  
  x1 <- 1
  
  for(i in 2:5000){
    x1 <- c( x1, myMCMC_step(x1[i-1] , f, dat0 ) )
  }

  visits <- table( x1[1:n0] )
  
  par(mfrow=c(1,2))
  plot(x = 1:n0, y = x1[1:n0] , type = "p",
       xlim = c(1, n0), ylim = c(min(x1), max(x1)),
       main = paste("King Markov's travel until the", n0, "day"),
       xlab = "Day",
       ylab = "Islands")
  plot( data.frame(
    x = 1:5,
    y = c(90 ,180, 270, 360, 450)
  )  ,lwd = 4, col = "red", ylim = c(0, 500),
  xlim = c(1,5),
  xlab = "Islands")
  points(visits)
  # points(x = density(x1[1:n])$x, y = density(x1[1:n])$y*100,
  #      type = "l")
  legend("topleft",
         lty = c(1,1),
         col = c("black", "red"),
         legend =c("Number of King's visits", "Islands' population")
         )
  
  par(old.par)
})
```

# Introduction

## Introduction 1/3

<div class = "box">
* Bayesian Statistics predates NHST statistics about 150 years
  * Why we stopped using it?
  
* $P(\Theta_i|D) \propto P(D|\Theta_i) \times P(\Theta_i)$
  * $D = \{ X^{(1)}, \dots,X^{(n)} \}$
  * $P(D|\Theta_i) = \mathcal{L}_n(\theta|X^{(1)}, \dots,X^{(n)}) = \prod^n_{i=1}p_\theta(X^{(i)})$
  * $P(\Theta_i|D) \propto P(\Theta_i) \int_{\Theta_i} \mathcal{L}_n(\theta|D) dQ_i(\theta)$
  * The computation of the _Marginal Likelihood Integral_ is difficult.
  * Too difficult for complex models.
  
</div>
    
## Introduction 2/3

<div class = "box">
* Why we started again?
  * Approximate methods of inference (normal and Laplace approximations,
    quadrature approximations).
  * Stochastic simulation methods (Monte Carlo integration,
    resampling techniques, **Markov Chain Monte Carlo - MCMC**).

A MCMC can be defined as a

> stochastic process where the present state [is dependent from the
  previous state][^1], but past and future states are independent [@Gamerman2006]
  
* MCMCs are resilient to local maxima (or minima)

* MCMCs can estimate all posterior distribution forms, even never-seen-before distributions

* Multiple, independent chains
  
* Assuming independency of the draws:
  * $E[p(\theta|y)]\approx \frac{1}{T} \sum^T_{t=1} p(\theta_t|y)$
  
* However, in Bayesian Statistics samples do not need to be drawn independently
  [@kaplan2014bayesian]
  
</div>
  
[^1]: Author's presentation addition
  
## Introduction 3/3


<div class = "box">

> MCMC draws values of $\theta$ from approximate distributions, and correct them
  to better approximate the target posterior distribution $P(\Theta|D)$ [@gelman2013bayesian].

* The basic idea of a MCMC is:

1. it draws a sample ($\theta_t$) from the posterior distribution ($P(\Theta|D)$).
2. the new sample is tested against the previous one ($\theta_{t-1}$).
3. Generally speaking, if the probability of the new sample $\theta_t$ is
   greater than the old sample $\theta_{t-1}$, the new sample is accepted.
4. If it is not, in order to avoid *local minima (or maxima)*, an additional
  rule is applied to see if the new sample is accepted or not.
  
</div>

## Monte Carlo methods


<div class = "box">

* They are non-parametrical statistical tests,
  for the first time used by Enrico Fermi in
  1930 [@Metropolis1987]
* There are a lot of different approaches, but
  usually the general schema is the following.
  1. Define a domain of possible inputs.
  2. Randomly generate the data from a Probability Density Function.
  3. Apply an algorithm to the data.
  4. Aggregate the results.
  
</div>


## Markov Chains


<div class = "box">

* A Markov Chain is a random process, namely a function that creates random variables.
* It undergoes transitions from one state to another within
  a limited range of possible states.
* It is _memorless_: the next state only depends from the current one.
</div>

## Stationary distribution of a MCMC


<div class = "box">

Each $\theta_t$ is only dependent to $\theta_{t-1}$

Over a long sequence:

* The chain will "forget" its
  initial state $\theta_{t = 0}$
* The chain will converge to its _stationary distribution_ $P(\Theta|D)$
* The number of iterations necessary to reach the _stationary distribution_
  are known as _burn-in_ iterations
* $\overline{P}(\theta|D) = \frac{1}{T-m}\sum^T_{t=m+1}p(\theta_i|y)$
  * with $T$ = total number of iterations,
  * $m$ = total number of _burn-in_ iterations,
  * $p(\theta_i|y)$ the posterior distribution sampled at the $i^{th}$ iteration
  
</div>
  
## The most used typologies of MCMCs


<div class = "box">

1. Metropolis-Hasting algorithm
2. Gibbs' Sampling
3. Hamiltonian Markov Chains


</div>

# Metropolis-Hastings algorithm

## Metropolis-Hastings algorithm


<div class = "box">

1. a _candidate_ value $x$ is sampled from a so-called _proposal_ distribution
  ($q(\cdot|y_t)$)
2. the algorithm _accepts_ the candidate value with probability
  $p(y,x) = \min\Big\{1,\frac{p(x)q(y|x)}{p(y)q(x|y)}\Big\}$
  * $y$ is the current value of the distribution ($y_t$), while $x$ is the
    proposal for the next step of the MCMC, it is the "wannabe" $y_{t+1}$
  * If the probability of $x$ ($p(x)q(y|x)$) is greater than the probability of
    $y$ ($p(y)q(x|y)$),
    we will accept $x$ as the next step of the chain with probability = 1
  * Otherwise, we will accept $x$ as the new step of the chain with a
    probability that comes from the ratio of
    the probabilities
    
</div>
    
## Metropolis-Hastings algorithm example 1/6

```{r}
rm( list = ls() )

set.seed(5)
y <- rnorm(100, mean = 10, sd = 30) + rgamma(100, shape = 1, rate = 0.1)
x <- y * 0.3  + rnorm( 100 , sd = 5)

dat2D <- data.frame(x,y)

dens <- kde2d(dat2D$x, dat2D$y)

contour(dens)
points(x, y, col = "lightgrey")

dens2 <- kde2d(dat2D$x, dat2D$y, n = 100)

densfunc <- function(x, y, dens2 = dens2){
  
  sx <- which.min( abs(x - dens2$x) )
  sy <- which.min( abs(y - dens2$y) )
  
  return( dens2$z[sx,sy] )
}

```

## Metropolis-Hastings algorithm example 2/6

```{r}
N <- 20000
NN <- NNN <- 10000

xn <- rep(0,N)
yn <- rep(0,N)

## arbitrary starting
xn[1] <- -10  
yn[1] <- -10

set.seed( 5 )

for(i in 2:N){
  currentx <- xn[i-1]
  currenty <- yn[i-1]
  
  prop <- mvrnorm(n = 1, c(currentx, currenty), .4*diag(2))
  
  proposedx <- prop[1]
  proposedy <- prop[2]
  
  denominator <- densfunc( currentx, currenty, dens2 )
  numerator   <- densfunc( proposedx, proposedy, dens2 )
  
  A <-  min( numerator / denominator, 1 )
  
  pz <- runif(1)
  
  if( pz < A ){
    xn[i] = proposedx       # accept move with probabily min(1,A)
    yn[i] = proposedy       # accept move with probabily min(1,A)
  } else {
    xn[i] = currentx        # otherwise "reject" move, and stay where we are
    yn[i] = currenty        # otherwise "reject" move, and stay where we are
  }
}

contour(dens)
points(x, y, col = "lightgrey")
points(xn[1:N], yn[1:N], col = "red", pch = ".")
points(xn[(N-1000):N], yn[(N-1000):N], col = "blue", type = "l")
```

## Metropolis-Hastings algorithm example 3/6


```{r}
renderPlot({
  old.par <- par()
  
  set.seed(5)
  y <- rnorm(100, mean = 10, sd = 30) + rgamma(100, shape = 1, rate = 0.1)
  x <- y * 0.3  + rnorm( 100 , sd = 5)
  
  dat2D <- data.frame(x,y)
  
  dens <- kde2d(dat2D$x, dat2D$y)
  
  contour(dens)
  points(x, y, col = "lightgrey")
  
  dens2 <- kde2d(dat2D$x, dat2D$y, n = 100)
  
  densfunc <- function(x, y, dens2 = dens2){
    
    sx <- which.min( abs(x - dens2$x) )
    sy <- which.min( abs(y - dens2$y) )
    
    return( dens2$z[sx,sy] )
  }
  
  n <- as.numeric(input$N)
  
  myMCMC_step <- function(old_point, density_function){
    currentx <- old_point[1]
    currenty <- old_point[2]
    
    prop <- mvrnorm(n = 1, c(currentx, currenty), .4*diag(2))
    
    proposedx <- prop[1]
    proposedy <- prop[2]
    
    denominator <- density_function( currentx, currenty, dens2 )
    numerator   <- density_function( proposedx, proposedy, dens2 )
    
    A <-  min( numerator / denominator, 1 )
    
    pz <- runif(1)
    
    if( pz < A ){ # accept
      return( c( proposedx , proposedy ) )
    } else { # reject
      return( c( currentx , currenty ) )
    }
  }
  
  set.seed( 5 )
  
  N <- 20000

  xn <- matrix(ncol = 2, nrow = N)
  
  ## arbitrary starting
  xn[1,] <- c( -10, -10 )  
  
  for(i in 2:N){
    xn[i,] <- myMCMC_step(xn[i-1, ] , densfunc )
  }
  
  contour(dens, main = paste(n, "iterations"))
  points(x, y, col = "lightgrey")
  points(xn[1:n, 1], xn[1:n, 2], col = "red", pch = ".")
  points(xn[(n-500):n, 1], xn[(n-500):n, 2], col = "blue", type = "l")
  
},
height = 600)

sidebarPanel(
  sliderInput("N", label = "Number of MCMC's iterations:",
                min = 500, max = N, value = 500, step = 100),
  width = 15, height = 100
)
```  


## Metropolis-Hastings algorithm example 4/6


```{r}
renderPlot({
  old.par <- par()
  
  f <- function(x)
        0.3 * dnorm(x, mean = 90, sd = 20) +
        0.1 * dnorm(x, mean = 65, sd = 20) +
        0.4 * dnorm(x, mean = 30, sd = 10) +
        0.2 * dnorm(x, mean = 150, sd = 10) 

  dat <- c(rnorm(300, mean = 90, sd = 20),
           rnorm(100, mean = 65, sd = 20),
           rnorm(400, mean = 30, sd = 10),
           rnorm(200, mean = 150, sd = 10))
  
  n <- as.numeric(input$N1)
  
  myMCMC_step <- function(old_point, density_function){
      new_point <- rnorm(1, mean = old_point, sd = 50)
      
      ## Acceptance probability:
      alpha <- min(1, density_function(new_point) / density_function(old_point))
      
      ## Accept new point with probability alpha:
      if (runif(1) < alpha){
        return( new_point )
      } else {
        return( old_point )
      }
  }
  
  set.seed( 5 )
  
  x1 <- 95
  
  for(i in 2:5000){
    x1 <- c( x1, myMCMC_step(x1[i-1] , f ) )
  }
  
  par(mfrow=c(1,2))
  plot(x = 1:n, y = x1[1:n] , type = "l",
       xlim = c(1, n), ylim = c(min(x1), max(x1)),
       main = paste("Traceplot", n, "iterations"))
  plot(density(x1[1:n]), main = "Sampling distribution",
       ylim = c(0,0.015), xlim = c(-4,200))
  points(density(dat), type = "l", lwd = 4, col = "red")
  rug(x1[1:n])
  legend("topright",
         lty = c(1,1),
         col = c("black", "red"),
         legend =c("MCMC dsitribution", "Original distribution")
         )
  
  par(old.par)
},
height = 600)

sidebarPanel(
  sliderInput("N1", label = "Number of MCMC's iterations:",
                min = 100, max = 5000, value = 100, step = 100),
  width = 15, height = 100
)
```   

## Metropolis-Hastings algorithm example 5/6


<div class = "box">

Our posterior distribution to be sampled is the following:

$y \sim \mathcal{N}(\mu, \sigma)$

Where:

$(\mu|D) \sim \mathcal{N}(\overline{y}, 10)$
$(\sigma|D) \sim \Gamma \Big(\frac{n}{2}, \frac{2}{(n-1)s^2}\Big)$

with:

$s^2 = 6$ being the variance of the data
$\overline{y} = 15$ being the mean of the data
and we observed 30 data points

</div>

## Metropolis-Hastings algorithm example 6/6

```
ybar <- 15
s2   <- 6
tot  <- 30
```

```{r}

renderPlot({
  old.par <- par()
  
  ybar <- 15
  s2 <- 6
  tot <- 30
  NN <- 10000
  
  n <- 1000 + as.numeric(input$N2)
  
  myMCMC_step <- function(old_mu, old_sigma, ybar, s2, tot ){
    
    currentx <- as.numeric( old_mu )
    currenty <- as.numeric( old_sigma )
    
    proposedx <- rnorm(n = 1, mean = ybar, sd = sqrt(10))  
    proposedy <- rgamma(n = 1, shape = tot / 2,
                        scale = 2 / ((tot - 1) * s2))
    
    outx <- NA
    outy <- NA
    
    denominatorx <- dnorm(currentx,  mean = ybar, sd = sqrt(10)) 
    numeratorx   <- dnorm(proposedx, mean = ybar, sd = sqrt(10)) 
    
    Ax <-  min( numeratorx / denominatorx, 1 )
    
    pz <- runif(1)
    
    if( pz < Ax ){ # accept
      outx <- proposedx
    } else { # reject
      outx <- currentx
    }
    
    denominatory <- dgamma(currenty,  shape = tot / 2,
                        scale = 2 / ((tot - 1) * s2)) 
    numeratory   <- dgamma(proposedy, shape = tot / 2,
                        scale = 2 / ((tot - 1) * s2)) 
    
    Ay <-  min( numeratory / denominatory, 1 )
    
    pz <- runif(1)
    
    if( pz < Ay ){ # accept
      outy <- proposedy
    } else { # reject
      outy <- currenty
    }
    
    
    
    return(data.frame( mu = outx,
                       sigma = outy))
  }
  
  set.seed( 5 )

  xn <- list()
  
  ## arbitrary starting
  xn[[1]] <- data.frame( mu = -10, sigma = 10  )  
  
  for(i in 2:(NN+1000)){
    xn[[i]] <- myMCMC_step(old_mu = xn[[i-1]][1],
                           old_sigma = xn[[i-1]][2] ,
                           ybar = ybar,
                           s2 = s2,
                           tot = tot)
    
    if(is.nan(xn[[i-1]][2,1])) break;
  }
  
  xn <- do.call("rbind", xn)
  
  # contour(dens, main = paste(n, "iterations"))
  # points(x, y, col = "lightgrey")
  plot(xn[1000:n, 1], xn[1000:n, 2], col = "red",
       ylim = c(0,0.3),
       xlim = c(5, 25),
       ylab = "sigma",
       xlab = "mu")
  points(xn[(n-100):n, 1], xn[(n-100):n, 2], col = "blue", type = "l")
  
}, height = 600)

sidebarPanel(
  sliderInput("N2", label = "Number of MCMC's iterations:",
                min = 1000, max = NN, value = 1000, step = 100),
  width = 15, height = 100
)
```  
  
# Gibbs' sampling

## Gibbs' sampling


<div class = "box">

1. our goal is to obtain the _joint_ posterior distributions of two or more
  parameters of a model ($P(\theta_1, \theta_2, \dots, \theta_n | D)$).
2. the algorithm starts with an initial set of parameters
  $\theta^{t=0} = \{ \theta_1^{t=0}, \theta_2^{t=0}, \dots, \theta_n^{t=0} \}$
3. then, it generates $\theta^t$ from $\theta^{t-1}$, and each parameter
  will be dependent from the states of the other parameters sequentially.
  *   The first parameter $\theta^t_1$ will be dependent from the states of
      $\{\theta_2^{t-1}, \theta_3^{t-1}, \dots, \theta_n^{t-1}\}$
  *   The second parameter $\theta^t_2$ will be dependent from the states of
      $\{\theta_1^{t}, \theta_3^{t-1}, \dots, \theta_n^{t-1}\}$
  *   The third parameter $\theta^t_3$ will be dependent from the states of
      $\{\theta_1^{t}, \theta_2^{t}, \dots, \theta_n^{t-1}\}$
  * ...
  
</div>
  
  
## Gibbs' sampling Example 1/3


<div class = "box">

We want to estimate the joint posterior distribution for
$\mathcal{N}(\mu,\sigma)$.

<table  class="tg">
<thead>
<tr>
<th>t for $\mu$</th>
<th>t for $\sigma$</th>
<th>$\mu$</th>
<th>$\sigma$</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>$\mu^{t=1} \sim p(\mu\rvert\sigma^{t=0})$ = 5</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>5</td>
<td>$\sigma^{t=1} \sim p(\sigma\rvert\mu^{t=1})$ = 2</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>$\mu^{t=2} \sim p(\mu\rvert\sigma^{t=1})$ = 7</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>7</td>
<td>$\sigma^{t=2} \sim p(\sigma\rvert\mu^{t=2})$ = 4</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>

</div>

## Gibbs' sampling Example 2/3


<div class = "box">

Our posterior distribution to be sampled is the following:

$y \sim \mathcal{N}(\mu, \sigma)$

Where:

$(\mu|\sigma, D) \sim \mathcal{N}(\overline{y}, n \cdot \sigma)$
$(\sigma|\mu, D) \sim \Gamma \Big(\frac{n}{2}, \frac{2}{(n-1)s^2+n(\mu-\overline{y})^2} \Big)$

with:

$s^2 = 6$ being the variance of the data
$\overline{y} = 15$ being the mean of the data
and we observed 30 data points

</div>


## Gibbs' sampling Example 3/3

```
ybar <- 15
s2   <- 6
tot  <- 30
```

```{r}

renderPlot({
  old.par <- par()
  
  ybar <- 15
  s2 <- 6
  tot <- 30
  NNN <- 10000
  
  n <- 1000 + as.numeric(input$N5)
  
  myMCMC_step <- function(old_mu, old_sigma, ybar, s2, tot ){
    
    currentx <- old_mu
    currenty <- old_sigma
    
    proposedx <- rnorm(n = 1, mean = ybar, sd = sqrt((tot * currenty)))  
    proposedy <- rgamma(n = 1, shape = tot / 2,
                        scale = 2 / ((tot - 1) * s2 + tot *
                                       (proposedx - ybar)^2))
    
    return(data.frame( mu = c(proposedx, proposedx),
                       sigma = c( currenty, proposedy)))
  }
  
  set.seed( 5 )

  xn <- list()
  
  ## arbitrary starting
  xn[[1]] <- data.frame( mu = c(-10, -10), sigma = c(10, 10 ) )  
  
  for(i in 2:(NNN+ 1000)){
    xn[[i]] <- myMCMC_step(xn[[i-1]][2,1],
                           xn[[i-1]][2,2] ,
                           ybar = ybar,
                           s2 = s2,
                           tot = tot)
    
    if(is.nan(xn[[i-1]][2,1])) break;
  }
  
  xn <- do.call("rbind", xn)
  
  # contour(dens, main = paste(n, "iterations"))
  # points(x, y, col = "lightgrey")
  plot(xn[1000:n, 1], xn[1000:n, 2], col = "red",
       ylim = c(0,0.3),
       xlim = c(5, 25),
       ylab = "sigma",
       xlab = "mu")
  points(xn[(n-500):n, 1], xn[(n-500):n, 2], col = "blue", type = "l")
  
0},
height = 600)

sidebarPanel(
  sliderInput("N5", label = "Number of MCMC's iterations:",
                min = 1000, max = NNN, value = 1000, step = 100),
  width = 15, height = 100
)
```  

# Hamiltonian Markov Chains

## Hamiltonian Markov Chains


<div class = "box">

Both Metropolis-Hastings and Gibbs' MCMCs are _random walk_ algorithms

> Random walk algorithms: stochastic processes, consisting in random steps, used to describe a pattern

* The Hamiltonian MC (also called hybrid Markov Chain) tries to limit the random walk behaviour of Metropolis' MCMC by means of a deterministic simulation methods [@gelman2013bayesian] 

1. for each
  parameter ($\theta_1, \theta_2, \dots, \theta_n$) we estimate a $P(\theta_j|D)$ and an independent $P(\phi_j)$.
2. $P(\theta_j,\phi_j|D) = P(\theta_j|D) \cdot P(\phi_j)$
3. $P(\phi)$ usually comes from a multinormal distribution $P(\phi) \sim Multi\mathcal{N}(0, M)$
4. Each iteration is:
  * Updating $\phi$ with a random draw from its posterior distribution
  * Simultanously update $\theta$ and $\phi$ in $L$ ~leapfrog~ steps where the log-density of $\theta$ is used to update $\phi$, and the log-density of $\phi$ is used to update $\theta$. The final values will be $\theta^*$ and $\phi^*$
  *
$$
\theta^t = \begin{cases}
    \theta^* & \text{with probability} \min \Big(1, \frac{p(\theta^*|D)p(\phi^*)}{p(\theta^{t-1}|D)p(\phi^{t-1})} \Big) \\
    \theta^{t-1} & \text{otherwise.}
\end{cases}
$$

</div>

# Diagnostics

## The scale-reduction factor $\hat{R}$, or diagnostics of Gelman and Rubin [@Gelman1992] 


<div class = "box">

Each one of the $m$ chains is composed by $n$ iterative draws of the $\theta$ parameters.

* There is a _Between-sequences_ variance: the variance of single chain over the mean of all chains, for each $\theta$ parameter $B = \frac{n}{m+1}\sum^n_{j=1}(\overline{\theta}_{\cdot j} - \overline{\theta}_{\cdot \cdot})^2$
* _Within-sequences_ variance: the mean of the variances for each $\theta$ for each chain: $W = \frac{1}{m}\sum^m_{j=1}s^2_j$, where $s^2_j = \frac{1}{n-1}\sum^n_{i=1}(\theta_{ij}-\overline{\theta}_{\cdot j})^2$

* $\hat{R} = \sqrt{\frac{\frac{n-1}{n}W + \frac{1}{n}B}{W}}$

* When $\hat{R} \leq 1.1$ we consider the chains as not divergent [@gelman2013bayesian, p. 288]


```{r, fig.width=12, fig.height=3}
x <- example_mcmc_draws(chains = 4, params = 1)

# trace plots of the betas
color_scheme_set("viridis")
mcmc_trace(x, regex_pars = "alpha")
```

</div>

## Effective Sample Size (ESS) or Effective number of simulation draws ($\hat{n}_{eff}$)


<div class = "box">

**It has nothing to do with the Sample Size of a study**

- It is the estimation of the number of independent MCMC iterations
- It is extremely important if your statistics will rely on
  posterior distribution intervals [@Kruschke2014]
- $\hat{n}_{eff} = \frac{m\cdot n}{1+2\sum^T_{t=1}\hat{\rho}_t}$, with
  $\hat{\rho}_t$ being the autocorrelation estimate and $t$ its lag
- For [@gelman2013bayesian] $\hat{n}_{eff} \geq 10$, for [@Kruschke2014]
  $\hat{n}_{eff} \geq 10000$
  
</div>

## Posterior Predictive Checking 


<div class = "box">

Another extremely important test is the Posterior Predictive Checking, 
that helps us in understanding whether our model is really plausible given
our data.

* Posterior Predictive p-value (ppp): a comparison between the observed and the
  data simulated from the MCMCs
* $ppp = \frac{1}{S}\sum^S_{s=1}\big (T(y^{sim}_s,\theta_s) \geq T(y,\theta_s) \big )$,
  where $T$ is a test, $y$ are the observed data, and $y^{sim}$ are the
  simulated observations
* If the model represents the data, $ppp \approx 0.5$ [@Gelman2013]
  (the error of the estimated $y^{sim}$ compared to $y$ has mean = 0)

* The Posterior Predictive Checking can also be done using a graphical approach
  
```{r, fig.width=12, fig.height=3}
color_scheme_set("brightblue")
y <- example_y_data()
yrep <- example_yrep_draws()
ppc_dens_overlay(y, yrep[1:25, ])
```

</div>

## Predictive accuracy


<div class = "box">

> Predictive Accuracy: the ability of the model build on a dataset $D$, to
predict a new dataset $D^*$ ( future or out of sample data)
minimising the error

* How to assess predictive accuracy?
  1. **within-sample predictive accuracy**: the accuracy of the model in fitting
    the data used to estimate the model. Generally it is an overestimation of
    the actual predictive accuracy.
    log posterior predictive density: `lppd`
  2. **adjusted within-sample predictive accuracy**: AIC, DIC, WAIC and other
    criteria adjust lppd to give unbiased estimates. expected lppd: `elppd`
  3. **cross-validation**: Leave-P-Out and Leave-One-Out Cross Validation,
    fitting the model on training data and evaluating
    its predictive accuracy on a validation data set.
    
</div>

## Pareto Smoothed Importance Sampling (PSIS)


<div class = "box">

> Importance Sampling is a method used to compute estimations drawing a random
sample from a distribution that is an easier approximation of
the target distribution [@gelman2013bayesian; @vehtari2021pareto]

* it computes _importance ratios_ or _weights_ ($\omega(\theta^S)$), that are
  an index of the
  importance of the MCMC iterations
* the $\omega(\theta^S)$ can be described by a Pareto distribution,
  characterised by a shape ($k$) parameter [@vehtari2021pareto]
  
</div>

## Leaving-One-Out Cross-Validation and PSIS


<div class = "box">

By using the Leaving-one-out technique, we might estimate the
$k$ values from the $n$ models, removing one observation each time
($n$ is the number of observations).

* The $k$ parameter of the PSIS of each LOO model will be evaluated:
  1. if $k < 0.5$ everything is OK
  2. if $0.5 \leq k < 0.7$ we should be cautious
  3. if $k > 0.7$ the importance sampling shows some problems
  4. if $k > 1$ yhere are several observations which are highly influential,
      which indicates potential model misspecification

* by means of the `loo` package, we will have the percentage of times where
  we obtain these scores
  
* This methodology can also be used to chose the model that better
  _predicts_ the observed data
  
</div>
  
## Widely Applicable Information Criterion or Watanabe-Akaike Information Criterion (WAIC)


<div class = "box">

> Information Criteria: measures of predictive accuracy, typically defined
based on the _deviance_ (log predictive density of the data given a point
estimate of the fitted model multiplied by $-2$ ($-2 \log p(y|\hat{\theta})$)
[@gelman2013bayesian]

* Akaike Information Criterion is reliable when prior distributions are flat,
  $P(\theta|D) \sim M\mathcal{N}(\mu, \Omega)$ and we have a sample size much
  greater than the number of parameters [@statrethinkingbook]
* Deviance Information Criterion is an AIC able to deal with informative priors
* WAIC:
  - Calculated from the posterior
  - Point-wise
  - No posterior MultiNormal distribution is assumed
  - Let lppd be the log-pointwise-predictive density
  - Let $p_{WAIC}$ be the effective number of parameters
  - let $V(y_i)$ be the variance in log-likelihood of $y_i$ for each sample from the posterior distribution

* $WAIC = -2(lppd - p_{WAIC})$

* lppd = $\sum^N_{i = 1} log P(y_i)$

* $p_{WAIC} = \sum^N_{i = 1} log V(y_i)$

</div>

## References and footnotes

<div class = "box">

</div>
