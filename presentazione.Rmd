---
title: "Markov Chain Monte Carlo Sampling"
author: "Michele Scandola"
date: "$2^{nd}$ BayesHSC Summer School 2021"
font-family: 'Serif'
output:
  slidy_presentation: 
    incremental: yes
    logo: logo.jpeg
    footer: "M. Scandola - $2^{nd}$ BayesHSC Summer School 2021 - https://michelescandola.shinyapps.io/2021_-_sipf_webinar_bayesian/"
css: mystyle.css
bibliography: biblio.bib
runtime: shiny
---

```{r setup, include=FALSE}
# Presentazione preparata da Michele Scandola per la Summer School
# BayesHSC
# 31/05 - 6/08 del 2021
# 
# Licenza afl-3.0

library(fontawesome)
library(knitr)
library(DT)
library(HDInterval)
library(bayesplot)
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction 1/

* Bayesian Statistics predates NHST statistics about 150 years
  * Why we stopped using it?
  
* $P(\Theta_i|D) \propto P(D|\Theta_i) \times P(\Theta_i)$
  * $D = \{ X^{(1)}, \dots,X^{(n)} \}$
  * $P(D|\Theta_i) = \mathcal{L}_n(\theta|X^{(1)}, \dots,X^{(n)}) = \prod^n_{i=1}p_\theta(X^{(i)})$
  * $P(\Theta_i|D) \propto P(\Theta_i) \int_{\Theta_i} \mathcal{L}_n(\theta|D) dQ_i(\theta)$
  * The computation of the _Marginal Likelihood Integral_ is difficult.
  * Too difficult for complex models.
    
## Introduction 2/

* Why we started again?
  * Because Markov Chain Monte Carlo sampling methods can avoid
    us to compute the integrals.
  * Markov Chain Monte Carlo draws samples from the posterior distribution.
  
* If the samples 





## Monte Carlo Markov Chains 1/3

- Algoritmo di campionamento casuale da una distribuzione (Monte Carlo)
- Ogni nuovo campionamento è dipendente dal campionamento precedente (Markov Chain)

```{r}
f <- function(x)
  0.3 * dnorm(x, mean = 90, sd = 20) +
  0.1 * dnorm(x, mean = 65, sd = 20) +
  0.4 * dnorm(x, mean = 30, sd = 10) +
  0.2 * dnorm(x, mean = 150, sd = 10) 

dat <- c(rnorm(300, mean = 90, sd = 20),
         rnorm(100, mean = 65, sd = 20),
         rnorm(400, mean = 30, sd = 10),
         rnorm(200, mean = 150, sd = 10))

curve(f(x), col="red", -4, 200, n=301, las=1)
```

## Monte Carlo Markov Chains 2/3

```{r}
sidebarPanel(
  sliderInput("N", label = "Numero di iterazioni della MCMC:",
                min = 100, max = 5000, value = 100, step = 100),
  width = 15
)

renderPlot({
  old.par <- par()
  
  f <- function(x)
        0.3 * dnorm(x, mean = 90, sd = 20) +
        0.1 * dnorm(x, mean = 65, sd = 20) +
        0.4 * dnorm(x, mean = 30, sd = 10) +
        0.2 * dnorm(x, mean = 150, sd = 10) 

  dat <- c(rnorm(300, mean = 90, sd = 20),
           rnorm(100, mean = 65, sd = 20),
           rnorm(400, mean = 30, sd = 10),
           rnorm(200, mean = 150, sd = 10))
  
  n <- as.numeric(input$N)
  
  myMCMC_step <- function(old_point, density_function){
      new_point <- rnorm(1, mean = old_point, sd = 50)
      
      ## Acceptance probability:
      alpha <- min(1, density_function(new_point) / density_function(old_point))
      
      ## Accept new point with probability alpha:
      if (runif(1) < alpha){
        return( new_point )
      } else {
        return( old_point )
      }
  }
  
  set.seed( 5 )
  
  x1 <- 95
  
  for(i in 2:5000){
    x1 <- c( x1, myMCMC_step(x1[i-1] , f ) )
  }
  
  par(mfrow=c(1,2))
  plot(x = 1:n, y = x1[1:n] , type = "l",
       xlim = c(1, n), ylim = c(min(x1), max(x1)),
       main = paste("Traceplot", n, "iterazioni"))
  plot(density(x1[1:n]), main = "Sampling distribution",
       ylim = c(0,0.015), xlim = c(-4,200))
  points(density(dat), type = "l", lwd = 4, col = "red")
  rug(x1[1:n])
  legend("topright",
         lty = c(1,1),
         col = c("black", "red"),
         legend =c("Dist. da MCMC", "Dist. originale")
         )
  
  par(old.par)
})
```

## Monte Carlo Markov Chains 3/3

Elementi da considerare delle MCMC per capire la qualità del campionamento:

- Burn-in iterations
- (optional) Adaptation iterations
- Numero di catene
- Numero di iterazioni "valide"
  (Tot iterations - Burn-in iterations) $\times$ Numero di catene
- Effective Sample Size (ESS o n_eff) $\leftarrow$ su questo torneremo dopo
- Diagnostica di Gelman-Rubin o $\hat{R}$ (`Rhat`) $\leftarrow$ su
  questo torneremo dopo
- Posterior predicitve checking, o posterior predictive p-value $\leftarrow$ su
  questo torneremo dopo
- ... 
